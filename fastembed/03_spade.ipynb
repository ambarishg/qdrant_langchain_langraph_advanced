{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5979890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ambarish\\qdrant_examples\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastembed import SparseTextEmbedding, SparseEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc23260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'prithivida/Splade_PP_en_v1',\n",
       "  'sources': {'hf': 'Qdrant/Splade_PP_en_v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Independent Implementation of SPLADE++ Model for English.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.532,\n",
       "  'additional_files': [],\n",
       "  'requires_idf': None,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'prithvida/Splade_PP_en_v1',\n",
       "  'sources': {'hf': 'Qdrant/Splade_PP_en_v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Independent Implementation of SPLADE++ Model for English.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.532,\n",
       "  'additional_files': [],\n",
       "  'requires_idf': None,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'Qdrant/bm42-all-minilm-l6-v2-attentions',\n",
       "  'sources': {'hf': 'Qdrant/all_miniLM_L6_v2_with_attentions',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Light sparse embedding model, which assigns an importance score to each token in the text',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': ['stopwords.txt'],\n",
       "  'requires_idf': True,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'Qdrant/bm25',\n",
       "  'sources': {'hf': 'Qdrant/bm25',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'mock.file',\n",
       "  'description': 'BM25 as sparse embeddings meant to be used with Qdrant',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.01,\n",
       "  'additional_files': ['arabic.txt',\n",
       "   'danish.txt',\n",
       "   'dutch.txt',\n",
       "   'english.txt',\n",
       "   'finnish.txt',\n",
       "   'french.txt',\n",
       "   'german.txt',\n",
       "   'greek.txt',\n",
       "   'hungarian.txt',\n",
       "   'italian.txt',\n",
       "   'norwegian.txt',\n",
       "   'portuguese.txt',\n",
       "   'romanian.txt',\n",
       "   'russian.txt',\n",
       "   'spanish.txt',\n",
       "   'swedish.txt',\n",
       "   'tamil.txt',\n",
       "   'turkish.txt'],\n",
       "  'requires_idf': True,\n",
       "  'vocab_size': 0},\n",
       " {'model': 'Qdrant/minicoil-v1',\n",
       "  'sources': {'hf': 'Qdrant/minicoil-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Sparse embedding model, that resolves semantic meaning of the words, while keeping exact keyword match behavior. Based on jinaai/jina-embeddings-v2-small-en-tokens',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': ['stopwords.txt',\n",
       "   'minicoil.triplet.model.npy',\n",
       "   'minicoil.triplet.model.vocab'],\n",
       "  'requires_idf': True,\n",
       "  'vocab_size': 19125}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseTextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4353f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Ambarish\\qdrant_examples\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ambarish Ganguly\\AppData\\Local\\Temp\\fastembed_cache\\models--Qdrant--Splade_PP_en_v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 5 files:  80%|████████  | 4/5 [00:42<00:10, 10.71s/it]\n",
      "\u001b[32m2025-08-24 21:27:17.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mfastembed.common.model_management\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m430\u001b[0m - \u001b[31m\u001b[1mCould not download model from HuggingFace: [WinError 1314] A required privilege is not held by the client: '..\\\\..\\\\blobs\\\\6112a1e6a41f32fd569b37b90c1b180c4218a119' -> 'C:\\\\Users\\\\Ambarish Ganguly\\\\AppData\\\\Local\\\\Temp\\\\fastembed_cache\\\\models--Qdrant--Splade_PP_en_v1\\\\snapshots\\\\efcd182bc7eb351e81a9445752d4388c2bab500b\\\\tokenizer_config.json' Falling back to other sources.\u001b[0m\n",
      "\u001b[32m2025-08-24 21:27:17.843\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mfastembed.common.model_management\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m452\u001b[0m - \u001b[31m\u001b[1mCould not download model from either source, sleeping for 3.0 seconds, 2 retries left.\u001b[0m\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00,  8.69it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prithivida/Splade_PP_en_v1\"\n",
    "# This triggers the model download\n",
    "model = SparseTextEmbedding(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045b58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents: list[str] = [\n",
    "    \"Chandrayaan-3 is India's third lunar mission\",\n",
    "    \"It aimed to land a rover on the Moon's surface - joining the US, China and Russia\",\n",
    "    \"The mission is a follow-up to Chandrayaan-2, which had partial success\",\n",
    "    \"Chandrayaan-3 will be launched by the Indian Space Research Organisation (ISRO)\",\n",
    "    \"The estimated cost of the mission is around $35 million\",\n",
    "    \"It will carry instruments to study the lunar surface and atmosphere\",\n",
    "    \"Chandrayaan-3 landed on the Moon's surface on 23rd August 2023\",\n",
    "    \"It consists of a lander named Vikram and a rover named Pragyan similar to Chandrayaan-2. Its propulsion module would act like an orbiter.\",\n",
    "    \"The propulsion module carries the lander and rover configuration until the spacecraft is in a 100-kilometre (62 mi) lunar orbit\",\n",
    "    \"The mission used GSLV Mk III rocket for its launch\",\n",
    "    \"Chandrayaan-3 was launched from the Satish Dhawan Space Centre in Sriharikota\",\n",
    "    \"Chandrayaan-3 was launched earlier in the year 2023\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e070d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_embeddings_list: list[SparseEmbedding] = list(\n",
    "    model.embed(documents, batch_size=6)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c66775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseEmbedding(values=array([0.05297118, 0.01963523, 0.36459631, 1.3850863 , 0.7177673 ,\n",
       "       0.12668221, 0.46230301, 0.44677085, 0.26896784, 1.01519835,\n",
       "       1.5655309 , 0.29412222, 1.53102326, 0.59785557, 1.10018182,\n",
       "       0.02078478, 0.09956114, 0.44248319, 0.09748189, 1.53519809,\n",
       "       1.36765635, 0.15741026, 0.49882492, 0.38629016, 0.76612061,\n",
       "       1.25805044, 0.39058587, 0.27236632, 0.45152223, 0.48261952,\n",
       "       0.26085198, 1.35912836, 0.70710599, 1.71639538]), indices=array([ 1010,  1011,  1016,  1017,  2001,  2018,  2034,  2093,  2117,\n",
       "        2319,  2353,  2509,  2634,  2686,  2796,  2817,  2922,  2959,\n",
       "        3003,  3148,  3260,  3390,  3462,  3523,  3822,  4231,  4316,\n",
       "        4774,  5590,  5871,  6416, 11926, 12076, 16469]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "sparse_embeddings_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd7ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token at index 1010 has weight 0.05297117680311203\n",
      "Token at index 1011 has weight 0.019635232165455818\n",
      "Token at index 1016 has weight 0.36459630727767944\n",
      "Token at index 1017 has weight 1.3850862979888916\n",
      "Token at index 2001 has weight 0.7177672982215881\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Token at index {sparse_embeddings_list[0].indices[i]} has weight {sparse_embeddings_list[0].values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc38fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ambarish\\qdrant_examples\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ambarish Ganguly\\.cache\\huggingface\\hub\\models--Qdrant--Splade_PP_en_v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"Qdrant/Splade_PP_en_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbaeabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"chandra\": 1.716395378112793,\n",
      "    \"third\": 1.5655308961868286,\n",
      "    \"##ya\": 1.5351980924606323,\n",
      "    \"india\": 1.5310232639312744,\n",
      "    \"3\": 1.3850862979888916,\n",
      "    \"mission\": 1.3676563501358032,\n",
      "    \"lunar\": 1.3591283559799194,\n",
      "    \"moon\": 1.2580504417419434,\n",
      "    \"indian\": 1.1001818180084229,\n",
      "    \"##an\": 1.0151983499526978,\n",
      "    \"3rd\": 0.7661206126213074,\n",
      "    \"was\": 0.7177672982215881,\n",
      "    \"spacecraft\": 0.7071059942245483,\n",
      "    \"space\": 0.5978555679321289,\n",
      "    \"flight\": 0.49882492423057556,\n",
      "    \"satellite\": 0.4826195240020752,\n",
      "    \"first\": 0.4623030126094818,\n",
      "    \"expedition\": 0.45152223110198975,\n",
      "    \"three\": 0.4467708468437195,\n",
      "    \"fourth\": 0.44248318672180176,\n",
      "    \"vehicle\": 0.39058586955070496,\n",
      "    \"iii\": 0.38629016280174255,\n",
      "    \"2\": 0.36459630727767944,\n",
      "    \"##3\": 0.29412221908569336,\n",
      "    \"planet\": 0.27236631512641907,\n",
      "    \"second\": 0.2689678370952606,\n",
      "    \"missions\": 0.26085197925567627,\n",
      "    \"launched\": 0.15741026401519775,\n",
      "    \"had\": 0.12668220698833466,\n",
      "    \"largest\": 0.09956113994121552,\n",
      "    \"leader\": 0.09748189151287079,\n",
      "    \",\": 0.05297117680311203,\n",
      "    \"study\": 0.020784784108400345,\n",
      "    \"-\": 0.019635232165455818\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_tokens_and_weights(sparse_embedding, tokenizer):\n",
    "    token_weight_dict = {}\n",
    "    for i in range(len(sparse_embedding.indices)):\n",
    "        token = tokenizer.decode([sparse_embedding.indices[i]])\n",
    "        weight = sparse_embedding.values[i]\n",
    "        token_weight_dict[token] = weight\n",
    "\n",
    "    # Sort the dictionary by weights\n",
    "    token_weight_dict = dict(sorted(token_weight_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    return token_weight_dict\n",
    "\n",
    "# Test the function with the first SparseEmbedding\n",
    "print(json.dumps(get_tokens_and_weights(sparse_embeddings_list[index], tokenizer), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c5ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
