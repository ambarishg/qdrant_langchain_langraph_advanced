{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bf640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395e116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm():\n",
    "    # we are using gemini model. You can use different models.\n",
    "    from langchain.chat_models import init_chat_model\n",
    "    from dotenv import load_dotenv  # used to store secret stuff like API keys or configuration values\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    llm = init_chat_model(\n",
    "        \"azure_openai:gpt-4o\",\n",
    "        azure_deployment=\"gpt4o\",\n",
    "    )\n",
    "    metadata = f\"CRAG, gpt4o\"\n",
    "    return llm, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2374ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, metadata = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e9cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='transformer'\n",
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"transformer\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"\"\"\n",
    "        \n",
    "        Given a user question choose to route it to \n",
    "        transformer store or web search.\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "You are an expert at routing a user question to a \n",
    "transformer store or web search.\n",
    "Transformer store has information about transformer models, guides, and tutorials.\n",
    "Web search has information about current events and news.\n",
    "You must choose the most relevant datasource to answer the question.\n",
    "\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"What is the difference between GPT-4 and GPT-3?\"}\n",
    "    )\n",
    ")\n",
    "print(question_router.invoke({\"question\": \"What is the capital of India?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef73be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vectorstore(doc_splits,collection_name):\n",
    "\n",
    "    from langchain_qdrant import QdrantVectorStore\n",
    "    \n",
    "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': False}\n",
    "    hf_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "    )\n",
    "    \n",
    "    vectorstore = QdrantVectorStore.from_documents(\n",
    "        doc_splits,\n",
    "        embedding=hf_embeddings,\n",
    "        url=os.getenv(\"QDRANT_URL\"),\n",
    "        api_key=os.getenv(\"QDRANT_KEY\"),\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    return vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c8655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(docs_list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=50,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    return doc_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ca2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformers_doc = HuggingFaceDatasetLoader(\"m-ric/transformers_documentation_en\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformers_docs = transformers_doc.load()\n",
    "transformers_docs = preprocess_dataset(transformers_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transformers_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a217868",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_store = initialize_vectorstore(\n",
    "    preprocess_dataset(transformers_docs),\n",
    "    collection_name=\"transformers_docs\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
